最原始的服务器模型

```
int main(int argc, char* argv[])
{
    //1. 初始化阶段

    while (true)
    {
        //2. 利用 accept 函数接受连接，产生客户端 fd

        //3. 利用步骤 2 中的 fd 与某个客户端通信
    }

    //3. 资源清理

    return 0;
}
```

一个连接一个线程模型

```
充分利用多线程模型
为每个客户端连接创建一个线程

主线程钓accept接受连接后，为每个连接创建一个工作线程
```

```
/侦听线程
UINT WINAPI MyMainThread(LPVOID lPvoid)
{
    LOG_NORMAL("Start MyMainThread successfully, ThreadID = %u.", ::GetCurrentThreadId());

    UINT        nThreadID = 0;
    SOCKET        sListenSocket = (SOCKET)lPvoid;
    SOCKET        sClientSocket = 0;
    while (1)
    {
        //等待客户连接
        sockaddr_in clientAddr = { 0 };
        int clientAddrLength = sizeof(clientAddr);
        if ((sClientSocket = accept(sListenSocket, (struct sockaddr*)&clientAddr, &clientAddrLength)) == INVALID_SOCKET)
            break;

        LOG_NORMAL("New client connected: %s:%d", inet_ntoa(clientAddr.sin_addr), clientAddr.sin_port);

        //启动客户签到线程
        _beginthreadex(NULL, 0, MyChildThread, (LPVOID)sClientSocket, 0, &nThreadID);
    }

    closesocket(sListenSocket);
    return 0;
}
```

```
//接收连接线程
UINT WINAPI MyChildThread(LPVOID lPvoid)
{
    LOG_NORMAL("Start MyChildThread successfully, ThreadID = %u.", ::GetCurrentThreadId());

    //交易处理
    SOCKET sClientSocket = (SOCKET)lPvoid;
    CLIENTITEM    clientItem = { 0 };
    int nCmd = HandleClientMain(sClientSocket, &clientItem);

    LOG_NORMAL("Client cmd = %d", nCmd);
    if (nCmd == -1)
        closesocket(sClientSocket);
    else if (nCmd == CONN_MAIN)
        LoginTrans(sClientSocket, &clientItem);
    else
        InterTrans(sClientSocket, &clientItem, nCmd);
    return 0;
}
```

Reactor模式

```
将多个请求分发传递给服务处理器
服务器程序使用多路复用技术，同步派发请求给相关的请求处理程序

包含结构
```

![image-20210704223935784](C:\Users\Echo\AppData\Roaming\Typora\typora-user-images\image-20210704223935784.png)

one thread one loop

```
一个线程对应一个循环
往往有一个线程作为主线程  只负责接受连接并生成socket 然后传递给工作线程
一个工作线程就是一个subreactor  负责事件的读写和业务逻辑
```

```
//线程函数
void* thread_func(void* thread_arg)
{
    //这里做一些需要的初始化工作
    while (线程退出标志)
    {
  epoll_or_select_func();   //检测IO事件
  handle_io_events();       //收发数据
  handle_other_things();    //
    }
    //这里做一些需要的清理工具
}
```

```
该方法的优点：
1，主线程只负责处理连接，而不用处理较慢的网络IO
（防止线程忙于IO不能建立连接）
2.线程A接受连接产生的新socket，可以根据负载均衡，加到各个工作线程
平衡资源利用率
```

上述线程while循环存在的问题

```
1.如果不设置超时时间，
在无任何时间的情况下，线程会空转
2.如果设置超时时间
有可能阻塞在IO事件处等待，而不能及时处理handle_other_things的事件
```

解决方案

```
1，为epoll的设置超时时间，而对于handle_other_thing采取唤醒机制
通过为epollfd挂在一个特殊的fd

```

唤醒机制的实现

```
1.使用管道fd，
创建管道 pipe  一端绑定到epollfd
一端写入字节时就会唤醒

2.linux新增的eventfd
和管道的使用一样，只是创建一个事件fd

3.使用socketpair
一对相互连接的socket。
相当服务端和客户端的两个端点
```

handler_other_things的实现逻辑

```
从其他任务集合中取出任务来执行
在取任务的时候要加锁

相当于one loop one thread +线程池中的线程池

相当于消费者模型的消费者

其可以在while循环的任意位置，不一定在epoll和io事件后，，常成为钩子函数
```

可以在线程中做一些定时任务，需要定时器及对应的处理函数

```
check and handle timers( );
```

效率保障

```
为了保证loop结构
除了epoll_or_select_func步骤中的IO复用可能等待
其他步骤不能有阻塞流程的操作

即当其他的函数有耗时操作时需要开新的业务线程去处理。
```

